{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Message Brokers\n",
    "Message brokers are middleware that enable communication between different applications by translating messages from the formal messaging protocol of the sender to the formal messaging protocol of the receiver. They are primarily used for decoupling applications and enabling asynchronous communication.\n",
    "\n",
    "  1. Use Case: \"Suitable for scenarios where each message needs to be processed by a single consumer. Commonly used in distributed systems, microservices, and event-driven architectures.\"\n",
    "  2. Examples: \"RabbitMQ, ActiveMQ, Azure Service Bus, Amazon SQS, Mosquitto.\"\n",
    "  3. Protocols: \"Supports various messaging protocols such as AMQP, MQTT, STOMP, and others.\"\n",
    "  4. Pushed based model: Messages are pushed to consumers for processing.\n",
    "\n",
    "\n",
    "Considering Azure Service Bus as an example, it provides two messaging patterns: queues and topics. Queues are used for point-to-point communication, where each message is processed by a single consumer. Topics are used for publish-subscribe communication, where messages are delivered to multiple subscriptions. The choice between queues and topics depends on the specific use case and requirements of the application. Still it cannot replace the need for a database, as it is not designed for long-term storage of data.\n",
    "\n",
    "    |------------------|------------------------------------|---------------------------------------------|\n",
    "    | Feature          | Queues                             | Topics                                      |\n",
    "    |------------------|------------------------------------|---------------------------------------------|\n",
    "    | Purpose          | Point-to-point communication       | Publish-subscribe communication             |\n",
    "    | Message Handling | Processed by a single consumer     | Delivered to multiple subscriptions         |\n",
    "    | Use Case         | Task scheduling, load balancing    | Event distribution, notification systems    |\n",
    "    | Persistence      | Stored until consumed or expired   | Stored until consumed or expired            |\n",
    "    | Ordering         | FIFO message delivery              | Order maintained within a subscription      |\n",
    "    | Delivery         | Single consumer                    | Multiple consumers                          |\n",
    "    | State            | Stateless                          | Stateless                                   |\n",
    "    |------------------|------------------------------------|---------------------------------------------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Streaming Platforms\n",
    "Streaming platforms are systems that allow the continuous ingestion, processing, and delivery of data streams in real-time. They are essential for applications that require real-time analytics, monitoring, and event-driven architectures.\n",
    "\n",
    "1. Use Case: \"Ideal for scenarios where data needs to be processed and analyzed in real-time. Commonly used in IoT, Log Aggregation, Data Pipelines, financial services, and social media analytics.\"\n",
    "2. Examples: \"Apache Kafka, Amazon Kinesis, Google Cloud Pub/Sub, Azure Event Hubs.\"\n",
    "3. Protocols: \"Supports various streaming protocols such as Kafka protocol, HTTP/2, WebSockets, and others.\"\n",
    "4. Pull based model: Consumers pull data from the stream for processing.\n",
    "\n",
    "Considering Apache Kafka as an example, it provides a distributed streaming platform that can handle high throughput and low latency. Kafka is used for building real-time data pipelines and streaming applications. It allows for both publish-subscribe and point-to-point communication patterns. Kafka's storage mechanism ensures data durability and fault tolerance.\n",
    "\n",
    "        |------------------|---------------------------------------------|\n",
    "        | Feature          | Kafka                                       |\n",
    "        |------------------|---------------------------------------------|\n",
    "        | Purpose          | Distributed streaming platform              |\n",
    "        | Message Handling | Processed by multiple consumers             |\n",
    "        | Use Case         | Real-time analytics, data pipelines         |\n",
    "        | Persistence      | Durable storage with configurable retention |\n",
    "        | Ordering         | Guaranteed ordering within partitions       |\n",
    "        | Delivery         | Multiple consumers                          |\n",
    "        | State            | Stateful                                    |\n",
    "        |------------------|---------------------------------------------|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Apache Kafka\n",
    "\n",
    "Apache Kafka is a distributed streaming platform that is designed to handle high throughput and low latency. It is widely used for building real-time data pipelines and streaming applications. Kafka allows for both publish-subscribe and point-to-point communication patterns, making it a versatile choice for various use cases.\n",
    "\n",
    "### Key Features of Apache Kafka:\n",
    "1. **Distributed Architecture**: Kafka's distributed nature allows it to scale horizontally, handling large volumes of data across multiple servers.\n",
    "2. **High Throughput**: Kafka can process millions of messages per second, making it suitable for applications with high data ingestion rates.\n",
    "3. **Low Latency**: Kafka ensures low latency in message delivery, which is crucial for real-time applications.\n",
    "4. **Durable Storage**: Kafka provides durable storage with configurable retention policies, ensuring data persistence and fault tolerance.\n",
    "5. **Fault Tolerance**: Kafka replicates data across multiple nodes, ensuring data availability even in the event of hardware failures.\n",
    "6. **Scalability**: Kafka can easily scale by adding more brokers to the cluster, accommodating increasing data loads.\n",
    "7. **Flexibility**: Kafka supports both publish-subscribe and point-to-point communication patterns, offering flexibility in data consumption and processing.\n",
    "8. **State Management**: Kafka can maintain state information, which is essential for complex event processing and stateful applications.\n",
    "\n",
    "### Common Use Cases:\n",
    "- **Real-time Analytics**: Kafka is used to process and analyze data in real-time, providing immediate insights and enabling quick decision-making.\n",
    "- **Data Pipelines**: Kafka serves as a backbone for data pipelines, ensuring reliable data flow between different systems and applications.\n",
    "- **Log Aggregation**: Kafka collects and aggregates logs from various sources, making it easier to monitor and analyze system behavior.\n",
    "- **Event Sourcing**: Kafka captures and stores events, allowing applications to reconstruct state and maintain consistency.\n",
    "\n",
    "Overall, Apache Kafka is a powerful and flexible streaming platform that is well-suited for modern data-driven applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "![Kafka Architecture](../images/kafka-architecture.png)\n",
    "\n",
    "\n",
    "### Components\n",
    "\n",
    "1. **Producers**: Publish messages to Kafka topics.\n",
    "2. **Kafka Cluster**: A group of brokers working together.\n",
    "3. **Brokers**: Servers in the Kafka cluster responsible for storing partitions and serving client requests.\n",
    "4. **KRaft (Kafka Raft Metadata Quorum)**: Manages metadata using the Raft consensus protocol, replacing ZooKeeper.\n",
    "5. **Topics and Partitions**: Topics are logical channels for categorizing messages, and partitions are subdivisions of a topic for scalability.\n",
    "6. **Consumer Groups**: A group of consumers working together subscribe to topics and process messages.\n",
    "\n",
    "### Kafka Workflow\n",
    "1. Producers push messages to topics in the Kafka cluster.\n",
    "2. Brokers within the cluster store and replicate data across partitions.\n",
    "3. Consumers in a consumer group consume messages from partitions for processing.\n",
    "4. KRaft ensures metadata management, leader election, and fault tolerance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Cluster\n",
    "\n",
    "\n",
    "![Kafka Cluster](../images/kafka-cluster.png)\n",
    "\n",
    "\n",
    "### Kafka Cluster\n",
    "- A **Kafka Cluster** is a distributed system composed of multiple brokers that work together to store and process real-time data streams.\n",
    "- It provides:\n",
    "  - **Scalability**: Handles increased workloads seamlessly by adding more brokers to the cluster.\n",
    "  - **Fault Tolerance**: Ensures data availability and fault tolerance by replicating partitions across brokers, allowing other brokers to take over responsibility in case of a failure..\n",
    "  - **High Availability**: Ensures seamless failover and leader election to maintain continuous service.\n",
    "  - **Partition Management**: Partitions are distributed across brokers for load balancing and parallel processing, with one broker serving as the leader and others acting as replicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Broker\n",
    "\n",
    "![Kafka Broker](../images/kafka-broker.png)\n",
    "\n",
    "- A **Kafka Broker** is a server within a Kafka Cluster that is responsible for storing and managing data streams (messages) sent by producers and consumed by consumers.\n",
    "- Each broker serves as a node in the distributed Kafka architecture and contributes to scalability, fault tolerance, and data distribution.\n",
    "\n",
    "#### Key Responsibilities:\n",
    "- **Partition Storage**:\n",
    "  - Each broker stores one or more partitions of topics, ensuring data durability and fault tolerance through replication.\n",
    "  - Brokers are assigned leader and follower roles for different partitions to manage read/write operations effectively.\n",
    "\n",
    "- **Processing Requests**:\n",
    "  - **From Producers**: Brokers handle incoming messages, appending them to the correct partition within a topic.\n",
    "  - **To Consumers**: Brokers serve messages to consumers from the specified partitions.\n",
    "\n",
    "- **Leader and Follower Roles**:\n",
    "  - Each partition has a leader broker that handles all read and write requests for that partition.\n",
    "  - Follower brokers replicate the leader's partition data for fault tolerance and act as backups in case the leader fails.\n",
    "\n",
    "- **Metadata Management**:\n",
    "  - Brokers maintain metadata about topics, partitions, and replicas, coordinating with the metadata manager (like KRaft or ZooKeeper) for updates.\n",
    "\n",
    "- **Scalability and Load Balancing**:\n",
    "  - By distributing partitions across multiple brokers, Kafka achieves high throughput and parallel processing.\n",
    "  - Brokers balance the workload by managing their assigned partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZooKeeper and KRaft in Kafka\n",
    "\n",
    "Kafka uses **ZooKeeper** (in older versions) or **KRaft (Kafka Raft)** (in newer versions) to manage metadata, leader elections, and cluster coordination.\n",
    "\n",
    "![Zookeeper/KRaft](../images/zookeeper-kraft.png)\n",
    "\n",
    "\n",
    "#### ZooKeeper\n",
    "\n",
    "- **Overview**:\n",
    "  - A centralized service used for distributed system coordination.\n",
    "  - Manages metadata such as brokers, topics, partitions, and their leaders.\n",
    "\n",
    "- **Key Responsibilities**:\n",
    "  - **Leader Election**: Coordinates which broker becomes the leader for a partition.\n",
    "  - **Metadata Management**: Stores metadata about brokers, topics, and partitions.\n",
    "  - **Cluster Coordination**: Ensures consistency and fault tolerance across the Kafka cluster.\n",
    "\n",
    "- **Challenges with ZooKeeper**:\n",
    "  - **Dependency**: Kafka clusters depend on an external ZooKeeper service.\n",
    "  - **Scalability**: ZooKeeper struggles with large-scale Kafka deployments.\n",
    "  - **Complexity**: Requires additional setup and maintenance.\n",
    "\n",
    "\n",
    "\n",
    "#### KRaft (Kafka Raft)\n",
    "\n",
    "- **Overview**:\n",
    "  - Introduced as a replacement for ZooKeeper.\n",
    "  - Built into Kafka, eliminating the need for an external dependency.\n",
    "\n",
    "- **Key Responsibilities**:\n",
    "  - **Leader Election**: Uses the Raft consensus algorithm to elect partition leaders.\n",
    "  - **Metadata Management**: Handles metadata natively within Kafka.\n",
    "  - **Fault Tolerance**: Ensures high availability and resilience through the Raft protocol.\n",
    "\n",
    "- **Advantages of KRaft**:\n",
    "  - **No External Dependency**: Simplifies the Kafka architecture.\n",
    "  - **Improved Scalability**: Designed for large-scale Kafka clusters.\n",
    "  - **Reduced Latency**: Optimized metadata propagation across brokers.\n",
    "\n",
    "\n",
    "#### Transition from ZooKeeper to KRaft\n",
    "\n",
    "| **Feature**               | **ZooKeeper**                       | **KRaft**                          |\n",
    "|---------------------------|-------------------------------------|-------------------------------------|\n",
    "| Metadata Management       | External (ZooKeeper service)       | Native to Kafka                     |\n",
    "| Leader Election Algorithm | ZooKeeper-based                    | Raft Consensus Algorithm            |\n",
    "| Setup Complexity          | Requires separate ZooKeeper setup  | Simplifies architecture             |\n",
    "| Scalability               | Limited by ZooKeeper performance   | Optimized for large-scale clusters  |\n",
    "| Dependency                | Requires ZooKeeper                 | No external dependency              |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Visual Workflow\n",
    "\n",
    "\n",
    "```plaintext\n",
    "ZooKeeper:\n",
    "Kafka Cluster → ZooKeeper (Manages metadata and leader election)\n",
    "\n",
    "KRaft:\n",
    "Kafka Cluster (Integrated metadata and leader election)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics and Partitions\n",
    "\n",
    "A **Kafka Topic** is a category or channel where messages are published by producers and consumed by consumers. Each topic is divided into multiple **partitions**, enabling scalability, parallel processing, and fault tolerance.\n",
    "\n",
    "![Topics and Partitions](../images/topics-partitions.png)\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "1. **Topic**:\n",
    "   - A Kafka Topic is a logical channel to which producers send messages.\n",
    "   - Topics are used to categorize messages, making it easier to consume relevant data.\n",
    "\n",
    "2. **Partition**:\n",
    "   - Each topic is divided into one or more partitions.\n",
    "   - A partition is an ordered, immutable sequence of messages.\n",
    "   - Messages within a partition are assigned unique offsets (0, 1, 2, etc.) to preserve order.\n",
    "\n",
    "3. **Parallelism**:\n",
    "   - Partitions enable parallelism as multiple consumers in a consumer group can process data from different partitions simultaneously.\n",
    "\n",
    "4. **Fault Tolerance**:\n",
    "   - Partitions are replicated across multiple brokers to ensure high availability.\n",
    "\n",
    "\n",
    "\n",
    "#### Example from the Image\n",
    "\n",
    "1. **Partition 0**:\n",
    "   - Contains messages with offsets: 0, 1, 2, 3, 4.\n",
    "   - Represents one slice of the topic's data.\n",
    "\n",
    "2. **Partition 1**:\n",
    "   - Contains messages with offsets: 0, 1, 2, 3.\n",
    "   - A separate slice of data that can be processed independently.\n",
    "\n",
    "3. **Partition 2**:\n",
    "   - Contains messages with offsets: 0, 1, 2, 3.\n",
    "   - Another independent slice of the topic's data.\n",
    "\n",
    "\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "1. **Producers**:\n",
    "   - Send messages to a topic.\n",
    "   - Messages are distributed across partitions (round-robin or based on a key).\n",
    "\n",
    "2. **Consumers**:\n",
    "   - Consume messages from partitions.\n",
    "   - Each consumer in a consumer group is assigned one or more partitions.\n",
    "\n",
    "3. **Order Guarantee**:\n",
    "   - Kafka guarantees the order of messages within a partition but not across partitions.\n",
    "\n",
    "4. **Scalability**:\n",
    "   - Adding more partitions increases parallelism, allowing more consumers to process data.\n",
    "\n",
    "\n",
    "\n",
    "#### Benefits of Partitioning\n",
    "\n",
    "- **Parallel Processing**:\n",
    "  - Multiple consumers can process data simultaneously, increasing throughput.\n",
    "\n",
    "- **Fault Tolerance**:\n",
    "  - Replication of partitions ensures data availability even if a broker fails.\n",
    "\n",
    "- **Scalability**:\n",
    "  - Adding partitions allows Kafka to handle increased producer and consumer workloads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Topic Messages and Offsets\n",
    "\n",
    "In Kafka, each **topic** is a log of events or messages, and each message in the topic is assigned a unique **offset**.\n",
    "\n",
    "\n",
    "![Kafka Topic Messages and Offsets](../images/offsets.png)\n",
    "\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "1. **Topic**:\n",
    "   - A topic is a logical channel for organizing and storing messages.\n",
    "   - Messages in a topic are stored in an immutable sequence.\n",
    "\n",
    "2. **Messages (M1, M2, ..., Mn)**:\n",
    "   - Messages are the data sent by producers.\n",
    "   - Each message in a topic represents an event, transaction, or log entry.\n",
    "\n",
    "3. **Offsets**:\n",
    "   - Each message within a partition of a topic has a unique sequential ID called an **offset**.\n",
    "   - Offsets act as a pointer to messages, allowing consumers to track where they left off.\n",
    "   - Example: The first message is assigned offset `0`, the second `1`, and so on.\n",
    "\n",
    "\n",
    "#### Example from the Image\n",
    "\n",
    "- **Topic**:\n",
    "  - Contains messages `M1, M2, ..., Mn` stored sequentially.\n",
    "\n",
    "- **Offsets**:\n",
    "  - Messages are indexed using offsets:\n",
    "    - Message `M1` → Offset `0`\n",
    "    - Message `M2` → Offset `1`\n",
    "    - Message `Mn` → Offset `n`\n",
    "\n",
    "\n",
    "#### How Offsets Work\n",
    "\n",
    "1. **Producers**:\n",
    "   - Append messages to the end of the topic, increasing offsets sequentially.\n",
    "\n",
    "2. **Consumers**:\n",
    "   - Read messages from a topic using offsets to keep track of the read position.\n",
    "   - Example: If a consumer processes message `M2` (offset `1`), it knows to fetch offset `2` next.\n",
    "\n",
    "3. **Log Retention**:\n",
    "   - Kafka retains messages for a configurable period or until storage limits are reached.\n",
    "   - Consumers must track offsets to avoid re-reading or missing messages.\n",
    "\n",
    "\n",
    "#### Benefits of Offsets\n",
    "\n",
    "- **Message Ordering**:\n",
    "  - Kafka guarantees that messages within a partition are read in the order of their offsets.\n",
    "\n",
    "- **Tracking Progress**:\n",
    "  - Consumers use offsets to track their progress in processing messages.\n",
    "\n",
    "- **Reprocessing**:\n",
    "  - Consumers can reprocess messages by resetting the offset to an earlier value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Message/Record Structure\n",
    "\n",
    "A **Kafka Message** is the fundamental unit of data in Kafka, created by the producer and sent to a topic. Each message contains multiple components, providing metadata and flexibility for reliable processing.\n",
    "\n",
    "\n",
    "![Kafka Message](../images/record-message.png)\n",
    "\n",
    "\n",
    "\n",
    "#### Components of a Kafka Message\n",
    "\n",
    "1. **Key (Binary)**:\n",
    "   - Represents the key associated with the message.\n",
    "   - Used to determine the partition for the message.\n",
    "   - Can be `null` if partitioning is not required.\n",
    "\n",
    "2. **Value (Binary)**:\n",
    "   - The actual data (payload) of the message.\n",
    "   - Can be `null` if only metadata is being sent.\n",
    "\n",
    "3. **Compression Type**:\n",
    "   - Defines the type of compression used for the message.\n",
    "   - Supported types: `none`, `gzip`, `snappy`, `lz4`, `zstd`.\n",
    "\n",
    "4. **Headers (Optional)**:\n",
    "   - Additional metadata in the form of key-value pairs.\n",
    "   - Useful for adding context without modifying the message payload.\n",
    "\n",
    "5. **Partition + Offset**:\n",
    "   - Specifies the partition the message belongs to and its unique offset within the partition.\n",
    "   - Guarantees the order of messages within the partition.\n",
    "\n",
    "6. **Timestamp**:\n",
    "   - Represents the time the message was created.\n",
    "   - Can be set by the producer (user-defined) or assigned by the Kafka broker (system-defined).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer Groups\n",
    "\n",
    "In Kafka, **consumer groups** are a mechanism to enable horizontal scalability and fault tolerance when consuming messages from topics.\n",
    "\n",
    "\n",
    "![Consumer Groups](../images/consumer-groups.png)\n",
    "\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "1. **Topic**:\n",
    "   - A logical channel that organizes data.\n",
    "   - Each topic is divided into multiple **partitions**, allowing data to be distributed and processed in parallel.\n",
    "\n",
    "2. **Partitions**:\n",
    "   - A single partition is a sequence of ordered messages.\n",
    "   - Partitions are processed independently and assigned to consumers within a group.\n",
    "\n",
    "3. **Consumer Groups**:\n",
    "   - A consumer group is a collection of consumers working together to consume data from a topic.\n",
    "   - Each consumer in the group processes messages from a unique set of partitions.\n",
    "\n",
    "\n",
    "#### Example from the Image\n",
    "\n",
    "1. **Partitions**:\n",
    "   - **Partition 0**: Contains messages with offsets `0, 1, 2, ..., 9`.\n",
    "   - **Partition 1**: Contains messages with offsets `0, 1, 2, ..., 6`.\n",
    "   - **Partition 2**: Contains messages with offsets `0, 1, 2, ..., 10`.\n",
    "   - **Partition 3**: Contains messages with offsets `0, 1, 2, ..., 5`.\n",
    "\n",
    "2. **Consumer Group**:\n",
    "   - **Consumer C1**:\n",
    "     - Assigned **Partition 0** and **Partition 3**.\n",
    "     - Processes all messages from these partitions.\n",
    "   - **Consumer C2**:\n",
    "     - Assigned **Partition 1**.\n",
    "     - Processes all messages from this partition.\n",
    "   - **Consumer C3**:\n",
    "     - Assigned **Partition 2**.\n",
    "     - Processes all messages from this partition.\n",
    "\n",
    "\n",
    "#### Workflow of Consumer Groups\n",
    "\n",
    "1. **Message Assignment**:\n",
    "   - Kafka assigns partitions to consumers in the group.\n",
    "   - Each partition is consumed by only one consumer in the group at a time.\n",
    "\n",
    "2. **Parallel Processing**:\n",
    "   - Messages from different partitions are processed in parallel by different consumers.\n",
    "\n",
    "3. **Rebalancing**:\n",
    "   - If a consumer joins or leaves the group, Kafka reassigns partitions to maintain balanced consumption.\n",
    "\n",
    "\n",
    "#### Benefits of Consumer Groups\n",
    "\n",
    "1. **Horizontal Scalability**:\n",
    "   - By adding more consumers to a group, partitions can be processed faster.\n",
    "\n",
    "2. **Fault Tolerance**:\n",
    "   - If a consumer fails, its assigned partitions are reassigned to other consumers in the group.\n",
    "\n",
    "3. **Order Guarantee**:\n",
    "   - Kafka ensures messages within a partition are consumed in order by the assigned consumer.\n",
    "\n",
    "\n",
    "#### Summary Workflow\n",
    "\n",
    "```plaintext\n",
    "Topic → Partitions → Consumer Group (C1, C2, C3)\n",
    "Partition 0 → C1\n",
    "Partition 1 → C2\n",
    "Partition 2 → C3\n",
    "Partition 3 → C1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
